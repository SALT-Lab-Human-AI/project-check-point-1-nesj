## Literature review

**Full Citation + Link:**  
Zhu, Y., Zeng, T., Li, X., Wu, X., & Li, R. (2025). Conversational Agents for Older Adults’ Health: A Systematic Literature Review. arXiv preprint arXiv:2503.23153. [https://arxiv.org/abs/2503.23153]

### Summary  
The paper highlights a gap between the potential benefits of Conversational Agents (CAs) and their actual adoption due to several concerns. With an aging global population putting pressure on healthcare systems, CAs are seen as a promising technological intervention. However, there is limited HCI research on older adults’ experiences and expectations.  

The authors conducted a systematic literature review of **72 papers (pre-2024)** using PRISMA guidelines. They analyzed older adults' characteristics, experiences, and expectations of CAs.  

**Key findings:**
- Growing interest in **chatbots and voice assistants**.  
- CAs are being used as **coaches, companions, monitors, and health information providers**.  
- **Low acceptance among older adults**, driven by concerns about unstable effects, loss of independence, stigma, and privacy issues.  
- Older adults expect:  
  - Natural language communication  
  - Multiple functions  
  - Personalization  
  - Strong user control  

---

### Insights  
1. **Low Acceptance and Multifaceted Concerns**  
   - Adoption is limited by **psychological and social fears** (privacy, data leakage, loss of independence, stigma).  
   - Projects should position CAs as **empowering companions** that enhance autonomy and privacy.  

2. **Evolving CA Landscape and Diverse Application Roles**  
   - Shift from **rule-based chatbots → generative AI** confirms relevance of LLM-based approaches.  
   - CAs now serve in multiple roles: **companion, coach, monitor, information provider**.  
   - Projects should **prioritize roles** to avoid feature bloat and maintain a coherent user experience.  

3. **Comprehensive User Expectations for Design**  
   - Seniors expect **fluent, adaptive conversations** → validates **voice-first approach** and high-quality TTS.  
   - Strong demand for **personalization and user control** (custom routines, data transparency).  
   - Systems should empower, not manage, older adults.  

---

### Limitations  
1. **Unsustainable Positive Effects & Evaluation Challenges**  
   - Benefits may fade due to the **novelty effect**.  
   - Lack of **longitudinal studies** makes long-term effectiveness unclear.  
   - Sustainable impact requires **personalized, adaptive systems** to maintain engagement.  

2. **Privacy Risks Amplified by Anthropomorphism**  
   - Human-like qualities may cause over-trust → seniors might **overshare sensitive data**.  
   - Ethical challenge: balance **compassionate design** with **transparent, secure data handling**.  
   - Developers should implement:  
     - Local data storage  
     - Clear consent mechanisms  
     - Transparent communication about data use  

---

---

## Literature review: AI Companions Reduce Loneliness  

**Full Citation + Link:**  
Mao, W., Luo, X., & Castelo, N. (2024). AI Companions Reduce Loneliness (Working Paper No. 24-078). Harvard Business School.(https://www.hbs.edu/ris/Publication%20Files/24-078_a3d2e2c7-eca1-4767-8543-122e818bf2e5.pdf)  

### Summary  
This paper investigates whether conversational AI companions can **alleviate loneliness**. Using novel methodologies, the researchers trained LLMs to **detect loneliness in conversations** and evaluated outcomes across six studies.  

**Key findings:**
- Interactions with AI companions **significantly reduced loneliness**, comparable to high-quality one-on-one human interaction.  
- AI outperformed other activities (e.g., watching YouTube) in alleviating loneliness.  
- Consumers often **underestimate** the positive impact of AI companions.  

---

### Insights  
1. **Core Problem Validation**  
   - Loneliness reduction is a **proven benefit** of conversational AI, strongly validating the project concept.  

2. **“Feeling Heard” as the Key Mechanism**  
   - The critical driver is users **feeling heard**—their thoughts and feelings being acknowledged with empathy and respect.  
   - AI companions can **mimic this mechanism**, providing therapeutic-like benefits.  

3. **Conversation Quality Matters**  
   - It’s not just about having a bot—it’s about **empathetic, meaningful interactions**.  
   - Reinforces the need for a **robust, empathetic conversational design**.  

---

### Limitations  
1. **Uncertainty of Long-Term Efficacy**  
   - Benefits shown over **1 week**; unclear if effects last over months or years.  
   - Risk of **novelty wearing off**, reducing long-term effectiveness.  

2. **Design and Cultural Specificity**  
   - Effectiveness tied to **caring, empathetic designs**.  
   - All studies conducted in the **US** → cultural generalizability (e.g., Japan, EU) remains uncertain.  

### Concrete Idea for our Project  
- Build a **robust memory cue system**: beyond remembering names, the CA could recall personal history (e.g., “favorite beach vacation,” “first car”) and weave these into conversations to create a more **personalized, human-like experience**. 
---
